一.定义：
1.如果不同类别的训练样例数目稍有差别，通常影响不大，但若差别很大，则会对学习过程造成困扰。例如有998个反例，但是正例只有2个，那么学习方法只需要返回一个永远将新样本预测为反例的学习器，
就能达到99.8%的精度；然而这样的学习器往往没有价值，因为它不能预测出任何正例。
2.类别不平衡（class-imbalance）就是指分类任务中不同类别的训练样例数目差别很大的情况。在现实的分类学习任务中，我们经常会遇到类别不平衡，例如在通过拆分法解决多分类问题时，即使原始问题中
不同类别的训练样例数目相当，在使用OvR（一对其余，One vs. Rest，简称OvR）、MvM（多对多，Many vs. Many，简称MvM）策略后产生的二分类任务扔可能出现类别不平衡现象，
因此有必要了解类别不平衡性处理的基本方法。
二.解决类别不平衡问题的方法
1.欠采样方法
1.1 定义：直接对训练集中多数类样本进行“欠采样”（undersampling），即去除一些多数类中的样本使得正例、反例数目接近，然后再进行学习。
1.2 随机欠采样方法：随机欠采样顾名思义即从多数类S中随机选择一些样本组成样本集E。然后将样本集E从S中移除,得到新的数据集SN=S-E。
缺点：随机欠采样方法通过改变多数类样本比例以达到修改样本分布的目的，从而使样本分布较为均衡，但是这也存在一些问题。对于随机欠采样，由于采样的样本集合要少于原来的样本集合，因此会造成一些信息缺失，
即将多数类样本删除有可能会导致分类器丢失有关多数类的重要信息。为了克服随机欠采样方法导致的信息缺失问题，又要保证算法表现出较好的不均衡数据分类性能，
出现了欠采样法代表性的算法EasyEnsemble和BalanceCascade算法。
